{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77a557df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: bs4 in c:\\users\\asus i3\\appdata\\roaming\\python\\python39\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3)\n"
     ]
    }
   ],
   "source": [
    "#Install the requests and BeautifulSoup Liararies\n",
    "!pip install bs4\n",
    "!pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b91c28d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17158849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 class=\"central-textlogo-wrapper\">\n",
      "<span class=\"central-textlogo__image sprite svg-Wikipedia_wordmark\">\n",
      "Wikipedia\n",
      "</span>\n",
      "<strong class=\"jsl10n localized-slogan\" data-jsl10n=\"portal.slogan\">The Free Encyclopedia</strong>\n",
      "</h1>\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "1 000 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "100 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "10 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "1 000+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "<h2 class=\"bookshelf-container\">\n",
      "<span class=\"bookshelf\">\n",
      "<span class=\"text\">\n",
      "<bdi dir=\"ltr\">\n",
      "100+\n",
      "</bdi>\n",
      "<span class=\"jsl10n\" data-jsl10n=\"portal.entries\">\n",
      "articles\n",
      "</span>\n",
      "</span>\n",
      "</span>\n",
      "</h2>\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "# 1) Write a python program to display all the header tags from wikipedia.org\n",
    "\n",
    "#send the request to the web page server to get the source code of the page\n",
    "\n",
    "page1=requests.get('https://www.wikipedia.org')\n",
    "page1\n",
    "\n",
    "soup1=BeautifulSoup(page1.content)\n",
    "soup1\n",
    "\n",
    "# to fetch the header tags\n",
    "header_tags=soup1.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "for i in header_tags:\n",
    "    print(i)\n",
    "print('End')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bdcd1106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9.0</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1941)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>M - Eine Stadt sucht einen Mörder</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1931)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Lawrence of Arabia</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1962)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Vertigo</td>\n",
       "      <td>8.2</td>\n",
       "      <td>(1958)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name Ratings Year of release\n",
       "0              The Shawshank Redemption     9.2          (1994)\n",
       "1                         The Godfather     9.2          (1972)\n",
       "2                       The Dark Knight     9.0          (2008)\n",
       "3                 The Godfather Part II     9.0          (1974)\n",
       "4                          12 Angry Men     9.0          (1957)\n",
       "..                                  ...     ...             ...\n",
       "95                         Citizen Kane     8.3          (1941)\n",
       "96    M - Eine Stadt sucht einen Mörder     8.3          (1931)\n",
       "97                   Lawrence of Arabia     8.3          (1962)\n",
       "98                   North by Northwest     8.2          (1959)\n",
       "99                              Vertigo     8.2          (1958)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2)Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)and make a dataframe\n",
    "\n",
    "page2=requests.get('https://www.imdb.com/chart/top/')\n",
    "page2\n",
    "\n",
    "soup2=BeautifulSoup(page2.content)\n",
    "soup2\n",
    "\n",
    "#scrap the names\n",
    "names=[]\n",
    "\n",
    "for i in soup2.find_all('td',class_=\"titleColumn\"):\n",
    "    names.append(i.text[15:-8])\n",
    "names\n",
    "\n",
    "#scrap ratings\n",
    "rate=[]\n",
    "for i in soup2.find_all('strong'):\n",
    "    rate.append(i.text)\n",
    "rate\n",
    "\n",
    "#scrap year of release\n",
    "year=[]\n",
    "for i in soup2.find_all('span',class_=\"secondaryInfo\"):\n",
    "    year.append(i.text)\n",
    "year\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Name':names,'Ratings':rate,'Year of release':year})\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c9c0ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Year of Release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ramayana: The Legend of Prince Ram</td>\n",
       "      <td>8.5</td>\n",
       "      <td>(1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rocketry: The Nambi Effec</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golmaa</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>777 Charli</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2022)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nayaka</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Kaakkaa Mutta</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2014)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ustad Hote</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Theeran Adhigaaram Ondr</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Angoo</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(1982)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rang De Basant</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2006)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Name Ratings Year of Release\n",
       "0    Ramayana: The Legend of Prince Ram     8.5          (1993)\n",
       "1             Rocketry: The Nambi Effec     8.4          (2022)\n",
       "2                                Golmaa     8.4          (1979)\n",
       "3                            777 Charli     8.4          (2022)\n",
       "4                                Nayaka     8.4          (1987)\n",
       "..                                  ...     ...             ...\n",
       "95                        Kaakkaa Mutta     8.0          (2014)\n",
       "96                           Ustad Hote     8.0          (2012)\n",
       "97              Theeran Adhigaaram Ondr     8.0          (2017)\n",
       "98                                Angoo     8.0          (1982)\n",
       "99                       Rang De Basant     8.0          (2006)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame\n",
    "page3=requests.get(\"https://www.imdb.com/india/top-rated-indian-movies/\")\n",
    "page3\n",
    "\n",
    "soup3=BeautifulSoup(page3.content)\n",
    "soup3\n",
    "\n",
    "#scrap names\n",
    "name3=[]\n",
    "for i in soup3.find_all('td',class_=\"titleColumn\"):\n",
    "    name3.append(i.text[15:-9])\n",
    "name3\n",
    "#scrap ratings\n",
    "rate3=[]\n",
    "for i in soup3.find_all('strong'):\n",
    "    rate3.append(i.text)\n",
    "rate3\n",
    "#scrap year of release\n",
    "year3=[]\n",
    "for i in soup3.find_all('span',class_=\"secondaryInfo\"):\n",
    "    year3.append(i.text)\n",
    "year3\n",
    "\n",
    "import pandas as pd\n",
    "df3=pd.DataFrame({'Name':name3,'Ratings':rate3,'Year of Release':year3})\n",
    "df3.head(100)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a888d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 25 July, 2017 to 25 July, 2022 ',\n",
       " 'kovind.nic.in',\n",
       " ' 25 July, 2012 to 25 July, 2017 ',\n",
       " 'kherjee.nic.in',\n",
       " ' 25 July, 2007 to 25 July, 2012 ',\n",
       " 'patil.nic.in',\n",
       " ' 25 July, 2002 to 25 July, 2007 ',\n",
       " 'am.nic.in',\n",
       " ' 25 July, 1997 to 25 July, 2002 ',\n",
       " ' 25 July, 1992 to 25 July, 1997 ',\n",
       " ' 25 July, 1987 to 25 July, 1992 ',\n",
       " ' 25 July, 1982 to 25 July, 1987 ',\n",
       " ' 25 July, 1977 to 25 July, 1982 ',\n",
       " ' 24 August, 1974 to 11 February, 1977',\n",
       " ' 3 May, 1969 to 20 July, 1969 and 24 August, 1969 to 24 August, 1974',\n",
       " ' 13 May, 1967 to 3 May, 1969',\n",
       " ' 13 May, 1962 to 13 May, 1967',\n",
       " ' 26 January, 1950 to 13 May, 1962',\n",
       " '2 The Rashtrapati Bhavan.',\n",
       " 'ed on: 22-July-2022 15:58 PM\\n',\n",
       " \"ed by National Informatics Centre. Website Content provided by the President's Secretariat.\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Write a python program to display list of respected former presidents of India(i.e. Name , Term of office) from https://presidentofindia.nic.in/former-presidents.htm\n",
    "page4=requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "page4\n",
    "\n",
    "soup4=BeautifulSoup(page4.content)\n",
    "soup4\n",
    "\n",
    "#scrap the names\n",
    "name4m=[]\n",
    "for i in soup4.find_all('h3'):\n",
    "    name4m.append(i.text[:-15])\n",
    "len(name4m)\n",
    "\n",
    "#scrap the term of office\n",
    "term4=[]\n",
    "for i in soup4.find_all('p'):\n",
    "    term4.append(i.text[15:])\n",
    "term4\n",
    "\n",
    "#import pandas as pd\n",
    "#df4=pd.DataFrame({'Name':name4m,'Term of Office':term4})\n",
    "#df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e45e50d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 a)Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape\n",
    "#a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "#b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "#c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "page5=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "page5\n",
    "\n",
    "soup5=BeautifulSoup(page5.content)\n",
    "soup5\n",
    "\n",
    "#scrap the top 10 ODI teams in men's Cricket\n",
    "teams5=[]\n",
    "for i in soup5.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    teams5.append(i.text)\n",
    "teams5\n",
    "#print(\"The length=\",len(teams5))\n",
    "\n",
    "#scrap matches records\n",
    "mrec=[]\n",
    "for j in soup5.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    mrec.append(j.text)\n",
    "mrec\n",
    "\n",
    "#scrap points records\n",
    "pts=[]\n",
    "for k in soup5.find_all('td',class_=\"\"):\n",
    "    pts.append(k.text)\n",
    "pts\n",
    "\n",
    "#scrap ratings records\n",
    "rr=[]\n",
    "for l in soup5.find_all('td',class_=\"\"):\n",
    "    rr.append(l.text)\n",
    "rr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c53d327c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsmen</th>\n",
       "      <th>Team</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Batsmen Team Rating\n",
       "0            Imam-ul-Haq  PAK    779\n",
       "1  Rassie van der Dussen   SA    766\n",
       "2        Quinton de Kock   SA    759\n",
       "3           David Warner  AUS    747\n",
       "4            Steve Smith  AUS    719\n",
       "5         Jonny Bairstow  ENG    710\n",
       "6            Virat Kohli  IND    707\n",
       "7           Rohit Sharma  IND    704\n",
       "8        Kane Williamson   NZ    701\n",
       "9           Fakhar Zaman  PAK    690"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 b)\n",
    "page5b=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "page5b\n",
    "soup5b=BeautifulSoup(page5b.content)\n",
    "soup5b\n",
    "\n",
    "#scrap Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "nn=[]\n",
    "for i in soup5b.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    nn.append(i.text[1:-1])\n",
    "nn\n",
    "\n",
    "#scrap team\n",
    "tt=[]\n",
    "for j in soup5b.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    tt.append(j.text[2:-1])\n",
    "tt\n",
    "\n",
    "#scrap rating\n",
    "rr=[]\n",
    "for k in soup5b.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rr.append(k.text)\n",
    "rr\n",
    "\n",
    "import pandas as pd\n",
    "df5b=pd.DataFrame({'Batsmen':nn,'Team':tt,'Rating':rr})\n",
    "df5b.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "456d4b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowlers Names</th>\n",
       "      <th>Teams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>FG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>FG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>NG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>FG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Andy McBrine</td>\n",
       "      <td>RE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>AN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Alzarri Joseph</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mitchell Santner</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lungi Ngidi</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bowlers Names Teams\n",
       "0      Josh Hazlewood    US\n",
       "1      Mitchell Starc    US\n",
       "2      Shaheen Afridi    AK\n",
       "3          Matt Henry     Z\n",
       "4          Adam Zampa    US\n",
       "5        Mehedi Hasan    AN\n",
       "6    Mujeeb Ur Rahman    FG\n",
       "7   Mustafizur Rahman    AN\n",
       "8         Rashid Khan    FG\n",
       "9        Chris Woakes    NG\n",
       "10      Mohammad Nabi    FG\n",
       "11       Andy McBrine    RE\n",
       "12     Jasprit Bumrah    ND\n",
       "13      Kagiso Rabada     A\n",
       "14    Shakib Al Hasan    AN\n",
       "15        Pat Cummins    US\n",
       "16     Alzarri Joseph     I\n",
       "17   Mitchell Santner     Z\n",
       "18        Lungi Ngidi     A"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5 c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "page5c=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/all-time-bowling\")\n",
    "page5c\n",
    "\n",
    "soup5c=BeautifulSoup(page5c.content)\n",
    "soup5c\n",
    "\n",
    "#scrap ODI bowlers\n",
    "bb=[]\n",
    "for i in soup5c.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    bb.append(i.text)\n",
    "bb\n",
    "#scrap teams\n",
    "t=[]\n",
    "for j in soup5c.find_all('td',class_=\"table-body__cell nationality-logo rankings-table__team\"):\n",
    "    t.append(j.text[3:-1])\n",
    "t\n",
    "#scrap ratings\n",
    "rr=[]\n",
    "for k in soup5c.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rr.append(k.text)\n",
    "rr\n",
    "\n",
    "import pandas as pd\n",
    "df5c=pd.DataFrame({'Bowlers Names':bb,'Teams':t,'})\n",
    "df5c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83cb2112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  Published Date  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "2                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "3                                 Boden, Margaret A.      August 1998   \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "5                                        Miller, Tim    February 2019   \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "14                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "15                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "19                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "22                      Kohavi, Ron, John, George H.    December 1997   \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "24                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8)Write a python program to scrape the details of most downloaded articles from AI in last 90 days.\n",
    "# https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "#Scrape below mentioned details :i) Paper Title ii) Authors iii) Published Date iv) Paper URL\n",
    "page8=requests.get(\"https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\")\n",
    "page8\n",
    "\n",
    "soup8=BeautifulSoup(page8.content)\n",
    "soup8\n",
    "\n",
    "#scrap paper title\n",
    "tit=[]\n",
    "for i in soup8.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\"):\n",
    "    tit.append(i.text)\n",
    "tit\n",
    "\n",
    "#scrap Authors\n",
    "auth=[]\n",
    "for j in soup8.find_all('span',class_=\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    auth.append(j.text)\n",
    "auth\n",
    "\n",
    "#scrap published date\n",
    "pud=[]\n",
    "for k in soup8.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\"):\n",
    "    pud.append(k.text)\n",
    "pud\n",
    "\n",
    "#scrap paper url\n",
    "url=[]\n",
    "for l in soup8.find_all('a',class_=\"sc-5smygv-0 fIXTHm\"):\n",
    "    url.append(l.get('href'))\n",
    "url\n",
    "\n",
    "import pandas as pd\n",
    "df8=pd.DataFrame({'Paper Title':tit,'Authors':auth,'Published Date':pud,'Paper URL':url})\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a9e7a90b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>News Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The 10 countries with the least paid vacation—...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/the-10-countri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Michigan couple makes $9,000/mo teaching peopl...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/michigan-coupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>These 10 cars have the greatest potential life...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/these-10-cars-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Startup backed by Tesla investor promises $300...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/alef-aeronauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manufacturing orders from China down 40% in de...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/manufacturing-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Death of the internal combustion engine — Cowe...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/death-of-the-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>These stocks are cheap heading into 2023, and ...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/these-stocks-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Who will be Disney's next CEO? Here are the to...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/disney-ceo-top...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Study: exercise may increase the effectiveness...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/study-exercise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>OPEC+ agrees to stick to its existing policy o...</td>\n",
       "      <td>6 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/12/04/opec-meeting-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Parking lots are becoming as important as cars...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/parking-lots-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Amazon's cloud unit faces cost-sensitive custo...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/aws-faces-cost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Don’t overlook this health warning on your dec...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/dont-overlook-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How electric air taxis could shake up the airl...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/how-electric-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I raised 2 successful CEOs and a doctor. Here'...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/i-raised-2-suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Delta pilots would get more than 30% in pay ra...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/delta-pilots-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Men participate less in 401(k) plans than wome...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/men-participat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The best U.S. states to raise a family if you ...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/best-states-ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Susan Cain: This Bob Dylan-inspired phrase can...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/bestselling-au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The difference between this comeback and the m...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/the-difference...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Goldman says buy these five stocks for the lon...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/goldman-says-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Celsius users with crypto collateral stuck tur...</td>\n",
       "      <td>December 3, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/03/celsius-users-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Cramer's lightning round: Let Extreme Networks...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Jim Cramer says these 3 apparel stocks benefit...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/jim-cramer-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Cramer’s week ahead: Markets need a strong job...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pro Picks: Watch all of Friday's big stock cal...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/pro-picks-watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>There is 'enormous opportunity' in REITs, says...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/reits-offer-en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Biden administration will end monkeypox public...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/biden-administ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Expect more choppiness ahead after a week of m...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/expect-more-ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>GM, LG investing $275 million to expand Tennes...</td>\n",
       "      <td>December 2, 2022</td>\n",
       "      <td>https://www.cnbc.com/2022/12/02/gm-lg-investin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline              Time  \\\n",
       "0   The 10 countries with the least paid vacation—...       3 Hours Ago   \n",
       "1   Michigan couple makes $9,000/mo teaching peopl...       4 Hours Ago   \n",
       "2   These 10 cars have the greatest potential life...       4 Hours Ago   \n",
       "3   Startup backed by Tesla investor promises $300...       4 Hours Ago   \n",
       "4   Manufacturing orders from China down 40% in de...       5 Hours Ago   \n",
       "5   Death of the internal combustion engine — Cowe...       5 Hours Ago   \n",
       "6   These stocks are cheap heading into 2023, and ...       5 Hours Ago   \n",
       "7   Who will be Disney's next CEO? Here are the to...       5 Hours Ago   \n",
       "8   Study: exercise may increase the effectiveness...       5 Hours Ago   \n",
       "9   OPEC+ agrees to stick to its existing policy o...       6 Hours Ago   \n",
       "10  Parking lots are becoming as important as cars...  December 3, 2022   \n",
       "11  Amazon's cloud unit faces cost-sensitive custo...  December 3, 2022   \n",
       "12  Don’t overlook this health warning on your dec...  December 3, 2022   \n",
       "13  How electric air taxis could shake up the airl...  December 3, 2022   \n",
       "14  I raised 2 successful CEOs and a doctor. Here'...  December 3, 2022   \n",
       "15  Delta pilots would get more than 30% in pay ra...  December 3, 2022   \n",
       "16  Men participate less in 401(k) plans than wome...  December 3, 2022   \n",
       "17  The best U.S. states to raise a family if you ...  December 3, 2022   \n",
       "18  Susan Cain: This Bob Dylan-inspired phrase can...  December 3, 2022   \n",
       "19  The difference between this comeback and the m...  December 3, 2022   \n",
       "20  Goldman says buy these five stocks for the lon...  December 3, 2022   \n",
       "21  Celsius users with crypto collateral stuck tur...  December 3, 2022   \n",
       "22  Cramer's lightning round: Let Extreme Networks...  December 2, 2022   \n",
       "23  Jim Cramer says these 3 apparel stocks benefit...  December 2, 2022   \n",
       "24  Cramer’s week ahead: Markets need a strong job...  December 2, 2022   \n",
       "25  Pro Picks: Watch all of Friday's big stock cal...  December 2, 2022   \n",
       "26  There is 'enormous opportunity' in REITs, says...  December 2, 2022   \n",
       "27  Biden administration will end monkeypox public...  December 2, 2022   \n",
       "28  Expect more choppiness ahead after a week of m...  December 2, 2022   \n",
       "29  GM, LG investing $275 million to expand Tennes...  December 2, 2022   \n",
       "\n",
       "                                            News Link  \n",
       "0   https://www.cnbc.com/2022/12/04/the-10-countri...  \n",
       "1   https://www.cnbc.com/2022/12/04/michigan-coupl...  \n",
       "2   https://www.cnbc.com/2022/12/04/these-10-cars-...  \n",
       "3   https://www.cnbc.com/2022/12/04/alef-aeronauti...  \n",
       "4   https://www.cnbc.com/2022/12/04/manufacturing-...  \n",
       "5   https://www.cnbc.com/2022/12/04/death-of-the-i...  \n",
       "6   https://www.cnbc.com/2022/12/04/these-stocks-a...  \n",
       "7   https://www.cnbc.com/2022/12/04/disney-ceo-top...  \n",
       "8   https://www.cnbc.com/2022/12/04/study-exercise...  \n",
       "9   https://www.cnbc.com/2022/12/04/opec-meeting-o...  \n",
       "10  https://www.cnbc.com/2022/12/03/parking-lots-b...  \n",
       "11  https://www.cnbc.com/2022/12/03/aws-faces-cost...  \n",
       "12  https://www.cnbc.com/2022/12/03/dont-overlook-...  \n",
       "13  https://www.cnbc.com/2022/12/03/how-electric-a...  \n",
       "14  https://www.cnbc.com/2022/12/03/i-raised-2-suc...  \n",
       "15  https://www.cnbc.com/2022/12/03/delta-pilots-w...  \n",
       "16  https://www.cnbc.com/2022/12/03/men-participat...  \n",
       "17  https://www.cnbc.com/2022/12/03/best-states-ra...  \n",
       "18  https://www.cnbc.com/2022/12/03/bestselling-au...  \n",
       "19  https://www.cnbc.com/2022/12/03/the-difference...  \n",
       "20  https://www.cnbc.com/2022/12/03/goldman-says-b...  \n",
       "21  https://www.cnbc.com/2022/12/03/celsius-users-...  \n",
       "22  https://www.cnbc.com/2022/12/02/cramers-lightn...  \n",
       "23  https://www.cnbc.com/2022/12/02/jim-cramer-say...  \n",
       "24  https://www.cnbc.com/2022/12/02/cramers-week-a...  \n",
       "25  https://www.cnbc.com/2022/12/02/pro-picks-watc...  \n",
       "26  https://www.cnbc.com/2022/12/02/reits-offer-en...  \n",
       "27  https://www.cnbc.com/2022/12/02/biden-administ...  \n",
       "28  https://www.cnbc.com/2022/12/02/expect-more-ch...  \n",
       "29  https://www.cnbc.com/2022/12/02/gm-lg-investin...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7)Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world : Headline,Time,News Link\n",
    "\n",
    "page7=requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "page7\n",
    "\n",
    "soup7=BeautifulSoup(page7.content)\n",
    "soup7\n",
    "\n",
    "#scrap Headline\n",
    "\n",
    "hl=[]\n",
    "for i in soup7.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    hl.append(i.text)\n",
    "hl\n",
    "\n",
    "#scrap time\n",
    "tim=[]\n",
    "for j in soup7.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "    tim.append(j.text)\n",
    "tim\n",
    "\n",
    "#scrap News Link\n",
    "lin=[]\n",
    "for k in soup7.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    lin.append(k.get('href'))\n",
    "lin\n",
    "\n",
    "import pandas as pd\n",
    "df7=pd.DataFrame({'Headline':hl,'Time':tim,'News Link':lin})\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1ac9bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resturant Name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.6</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Resturant Name  \\\n",
       "0      Castle BarbequeConnaught Place, Central Delhi   \n",
       "1  Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2  Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "3  Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "4  The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "5    India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8  Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "\n",
       "                         Cuisine  \\\n",
       "0          Chinese, North Indian   \n",
       "1   North Indian, Asian, Italian   \n",
       "2          Chinese, North Indian   \n",
       "3           Italian, Continental   \n",
       "4          North Indian, Chinese   \n",
       "5          North Indian, Italian   \n",
       "6                   North Indian   \n",
       "7                   North Indian   \n",
       "8          North Indian, Mughlai   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi     4.1   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "3  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "4                 Gardens Galleria,Sector 38A, Noida       4   \n",
       "5               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.6   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                           Image URL  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9) Write a python program to scrape mentioned details from dineout.co.in :i)Restaurant name ii)Cuisine iii)Location iv)Ratings v)Image URL\n",
    "page9=requests.get(\"https://www.dineout.co.in/delhi-restaurants/buffet-special\")\n",
    "page9\n",
    "\n",
    "soup9=BeautifulSoup(page9.content)\n",
    "soup9\n",
    "\n",
    "#scrap Restaurant name\n",
    "names9=[]\n",
    "for i in soup9.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    names9.append(i.text)\n",
    "names9\n",
    "#scrap Cuisune\n",
    "cur=[]\n",
    "for j in soup9.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cur.append(j.text.split('|')[1])\n",
    "cur\n",
    "#scrap Location\n",
    "loc=[]\n",
    "for k in soup9.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    loc.append(k.text)\n",
    "loc\n",
    "\n",
    "#scrap ratings\n",
    "rate=[]\n",
    "for l in soup9.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    rate.append(l.text)\n",
    "rate\n",
    "\n",
    "#scrap image URL\n",
    "img=[]\n",
    "for m in soup9.find_all('img',class_=\"no-img\"):\n",
    "    img.append(m.get('data-src'))    \n",
    "img\n",
    "\n",
    "import pandas as pd\n",
    "df9=pd.DataFrame({'Resturant Name':names9,'Cuisine':cur,'Location':loc,'Ratings':rate,'Image URL':img})\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "418d7596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Sensors</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication h5-median\n",
       "0     1.                                             Nature       667\n",
       "1     2.                The New England Journal of Medicine       780\n",
       "2     3.                                            Science       614\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...       627\n",
       "4     5.                                         The Lancet       635\n",
       "..   ...                                                ...       ...\n",
       "95   96.                       Journal of Business Research       233\n",
       "96   97.                                   Molecular Cancer       209\n",
       "97   98.                                            Sensors       201\n",
       "98   99.                              Nature Climate Change       228\n",
       "99  100.                    IEEE Internet of Things Journal       212\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10) Write a python program to scrape the details of top publications from Google Scholar from https://scholar.google.com/citations?view_op=top_venues&hl=en \n",
    "# Rank, Publication, h5-index, h5-median\n",
    "page10=requests.get(\"https://scholar.google.com/citations?view_op=top_venues&hl=en\")\n",
    "page10\n",
    "\n",
    "soup10=BeautifulSoup(page10.content)\n",
    "soup10\n",
    "\n",
    "#scrap the rank\n",
    "rank10=[]\n",
    "for i in soup10.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank10.append(i.text)\n",
    "rank10\n",
    "\n",
    "#scrap multiple publication names\n",
    "name10m=[]\n",
    "for j in soup10.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    name10m.append(j.text)\n",
    "name10m\n",
    "\n",
    "#scrap h5-index\n",
    "index10=[]\n",
    "for k in soup10.find_all('td',class_=\"gsc_mvt_n\"):\n",
    "    index10.append(k.text)\n",
    "index10\n",
    "\n",
    "#scrap h5-median\n",
    "med10=[]\n",
    "for l in soup10.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    med10.append(l.text)\n",
    "med10\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Rank':rank10,'Publication':name10m,'h5-median':med10})\n",
    "df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffceaac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
